{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/hackerearth-machine-learning-exhibit-art/dataset/train.csv')\ntest_data = pd.read_csv('/kaggle/input/hackerearth-machine-learning-exhibit-art/dataset/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"report_train = pandas_profiling.ProfileReport(train_data)\nreport_train.to_file(\"report_train.html\")\n\nreport_train\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"report_test = pandas_profiling.ProfileReport(test_data)\nreport_test.to_file(\"report_test.html\")\n\nreport_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.nunique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.nunique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged = pd.concat([train_data,test_data],axis = 0)\nmerged.dtypes.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_with_missing = (col for col in merged.columns \n                                 if merged[col].isnull().any())\n\nfor col in cols_with_missing:\n    merged[col + '_was_missing'] = merged[col].isnull()\n\ncolumns = ['Artist Reputation_was_missing', 'Height_was_missing',\n       'Width_was_missing', 'Weight_was_missing', 'Material_was_missing',\n       'Transport_was_missing', 'Remote Location_was_missing']\n\nfor col in columns:\n    result = merged[col].astype(int)\n    merged[col] = result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged['Missing_count'] = merged['Artist Reputation_was_missing'] + merged['Height_was_missing'] + merged['Width_was_missing'] + merged['Weight_was_missing'] + merged['Material_was_missing'] + merged['Transport_was_missing'] + merged['Remote Location_was_missing'] \nmerged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged = merged.drop(['Cost_was_missing'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_mod = merged.iloc[:6500, :]\ntest_data_mod = merged.iloc[6500:, :].drop(columns = ['Cost'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_mod['Missing_count'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp_tf = train_data_mod \n#exp_tf_filtered = exp_tf[exp_tf['Missing_count'] < 4] \nexp_tf_filtered = exp_tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp_tf_filtered['Artist Reputation'].fillna(exp_tf_filtered['Artist Reputation'].median(), inplace=True)\nexp_tf_filtered['Height'].fillna(exp_tf_filtered['Height'].median(), inplace=True)\nexp_tf_filtered['Width'].fillna(exp_tf_filtered['Width'].median(), inplace=True)\nexp_tf_filtered['Weight'].fillna(exp_tf_filtered['Weight'].median(), inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp_tf_filtered['Material'].fillna(exp_tf_filtered['Material'].mode()[0], inplace=True)\nexp_tf_filtered['Transport'].fillna(exp_tf_filtered['Transport'].mode()[0], inplace=True)\nexp_tf_filtered['Remote Location'].fillna(exp_tf_filtered['Remote Location'].mode()[0], inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp_tf_filtered.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_mod['Artist Reputation'].fillna(exp_tf_filtered['Artist Reputation'].median(), inplace=True)\ntest_data_mod['Height'].fillna(exp_tf_filtered['Height'].median(), inplace=True)\ntest_data_mod['Width'].fillna(exp_tf_filtered['Width'].median(), inplace=True)\ntest_data_mod['Weight'].fillna(exp_tf_filtered['Weight'].median(), inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_mod['Material'].fillna(exp_tf_filtered['Material'].mode()[0], inplace=True)\ntest_data_mod['Transport'].fillna(exp_tf_filtered['Transport'].mode()[0], inplace=True)\ntest_data_mod['Remote Location'].fillna(exp_tf_filtered['Remote Location'].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp_tf_filtered.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ndf = exp_tf_filtered.copy()\nsns.boxplot(x=df['Artist Reputation'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['Artist Reputation'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['Height'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(x=df['Height'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''q = df['Height'].quantile(0.999)\ndf_out1 = df[df['Height']>=q]\ndf = df[df['Height']<q]\n\nsns.distplot(x=df['Height'])'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=exp_tf_filtered['Width'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(x=df['Width'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''q2 = df['Width'].quantile(0.999)\ndf_out2 = df[df['Width']>=q2]\ndf = df[df['Width']<q2]\n\nsns.distplot(x=df['Width'])'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=exp_tf_filtered['Weight'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(x=df['Weight'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''q3 = df['Weight'].quantile(0.95)\ndf_out3 = df[df['Weight']>=q3]\ndf = df[df['Weight']<q3]\n\nsns.distplot(x=df['Weight'])'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=exp_tf_filtered['Price Of Sculpture'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(x=exp_tf_filtered['Price Of Sculpture'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''q4 = df['Price Of Sculpture'].quantile(0.99)\ndf_out4 = df[df['Price Of Sculpture']>=q4]\ndf = df[df['Price Of Sculpture']<q4]\n\nsns.distplot(x=df['Price Of Sculpture'])'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''dp_removed = pd.concat([df_out1,df_out2, df_out3, df_out4],axis = 0)\ndp_removed'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.reset_index(drop=True, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = exp_tf_filtered","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"target = df.Cost\ndf.drop('Cost', axis = 1, inplace = True)\ncooking_data = pd.concat([df,test_data_mod],axis = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cooking_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cooking_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cooking_data.nunique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cooking_data['Customer Location']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cooking_data['zip'] = cooking_data['Customer Location'].map(lambda x:x.split()[-1])\ncooking_data['zip'] = cooking_data['zip'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cooking_data.drop(['Customer Id', 'Artist Name', 'Customer Location'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unencoded_data = cooking_data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_data = unencoded_data[['Material', 'Transport']]\none_hot_data = pd.get_dummies(one_hot_data, drop_first=True, prefix=['Material', 'Transport'])\none_hot_data = one_hot_data.astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bool_data = unencoded_data[['International', 'Express Shipment', 'Installation Included', 'Fragile', 'Remote Location']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bool_data.replace(value = [1, 0], to_replace = ['Yes', 'No'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_data = unencoded_data[['Customer Information']]\nlabel_data.replace(value = [1, 0], to_replace = ['Wealthy', 'Working Class'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_data1 = unencoded_data['Scheduled Date']\ndate_data2 = unencoded_data['Delivery Date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_data1 = pd.to_datetime(date_data1)\ndate_data2 = pd.to_datetime(date_data2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_data2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_data1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days_diff = date_data2 - date_data1\ndays_diff = pd.to_numeric(days_diff)\ndays_diff = days_diff/(24*60*60*1000000000)\ndays_diff = days_diff.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_data = unencoded_data.select_dtypes(include = ['int64', 'float64'])\nnum_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cooked_data = pd.concat([num_data, one_hot_data, bool_data, label_data, days_diff],axis = 1)\ncooked_data = cooked_data.rename(columns = {0:\"Days_diff\"}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cooked_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cooked_data.drop(['Missing_count'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cooked_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_prepared =  cooked_data.iloc[:6500, :]\ntest_prepared = cooked_data.iloc[6500:, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_prepared","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_prepared","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\ntransformer = StandardScaler().fit(train_prepared)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_train_data = transformer.transform(train_prepared)\nscaled_test_data = transformer.transform(test_prepared)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_train_data = pd.DataFrame(data = scaled_train_data, columns = train_prepared.columns, index = train_prepared.index)\nscaled_test_data = pd.DataFrame(data = scaled_test_data, columns = test_prepared.columns, index = test_prepared.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaled_train_data = train_prepared\n#scaled_test_data = test_prepared","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = target.abs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(target)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels_mod = np.log1p(target)\n#train_labels_mod = target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train_labels_mod)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_transformer = StandardScaler().fit(target.values.reshape(-1, 1))\nscaled_target = target_transformer.transform(target.values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(scaled_target)\n#train_labels_mod = scaled_target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = scaled_train_data\ny = train_labels_mod\ndata = pd.concat([scaled_train_data, train_labels_mod],axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get correlations of each features in dataset\ncorrmat = data.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesRegressor\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesRegressor()\nmodel.fit(X,y)\nprint(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(20).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_importances.nlargest(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_cons = ['Artist Reputation', 'Height', 'Width', 'Weight', 'Price Of Sculpture',\n       'Base Shipping Price', 'Material_Brass', 'Material_Bronze',\n       'Material_Clay', 'Material_Marble', 'Material_Stone', 'Material_Wood',\n       'Transport_Roadways', 'Transport_Waterways', 'International',\n       'Express Shipment', 'Installation Included', 'Fragile',\n       'Remote Location', 'Customer Information', 'Days_diff']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_col = ['zip']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_train_data.drop(drop_col, axis = 1, inplace = True)\nscaled_test_data.drop(drop_col, axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaled_train_data = scaled_train_data[col_cons]\n#scaled_test_data = scaled_test_data[col_cons]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 43\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\n\nlinear = LinearRegression(n_jobs = -1)\nlasso = Lasso(random_state = seed)\nridge = Ridge(random_state = seed)\nelnt = ElasticNet(random_state = seed)\ndt = DecisionTreeRegressor(random_state = seed)\nknn = KNeighborsRegressor(n_jobs = -1)\nrf =  RandomForestRegressor(n_jobs = -1, random_state = seed)\net = ExtraTreesRegressor(n_jobs = -1, random_state = seed)\nab = AdaBoostRegressor(random_state = seed)\ngb = GradientBoostingRegressor(random_state = seed)\nxgb = XGBRegressor(random_state = seed, n_jobs = -1, learning_rate = 0.05, max_depth=6, n_estimators=1000)\nlgb = LGBMRegressor(random_state = seed, n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_r2(model):\n    model.fit(scaled_train_data,train_labels_mod)\n    return model.score(scaled_train_data,train_labels_mod)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [linear, lasso, ridge, elnt, dt, knn, rf, et, ab, gb, xgb, lgb]\ntraining_score = []\nfor model in models:\n    training_score.append(train_r2(model))\n    \ntrain_score = pd.DataFrame(data = training_score, columns = ['Training_R2'])\ntrain_score.index = ['LR', 'LSO', 'RIDGE', 'ELNT', 'DT', 'KNN', 'RF', 'ET', 'AB', 'GB', 'XGB', 'LGB']\ntrain_score = (train_score*100).round(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(train_score.index,train_score['Training_R2'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_test_split_score(model):\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import mean_squared_log_error\n    X_train, X_test, Y_train, Y_test = train_test_split(scaled_train_data, train_labels_mod, test_size = 0.2, random_state = seed)\n    model.fit(X_train, Y_train)\n    prediction = model.predict(X_test)\n    mse = mean_squared_error(prediction, Y_test)\n    rmse = np.sqrt(mse)\n    error_score = [rmse]\n    return error_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [linear,lasso, ridge, elnt, dt, knn, rf, et, ab, gb, xgb, lgb]\ntrain_test_split_rmse = []\n\nfor model in models:\n    train_test_split_rmse.append(train_test_split_score(model)[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_score = pd.DataFrame(data = train_test_split_rmse, columns = ['Train_Test_RMSE'])\ntrain_test_score.index = ['Linear','LSO', 'RIDGE', 'ELNT', 'DT', 'KNN', 'RF', 'ET', 'AB', 'GB', 'XGB', 'LGB']\nsns.scatterplot(train_test_score.index,train_test_score['Train_Test_RMSE'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cross_validate(model):\n    from sklearn.model_selection import cross_val_score\n    neg_x_val_score = cross_val_score(model, scaled_train_data, train_labels_mod, cv = 10, n_jobs = -1, scoring = 'neg_mean_squared_error')\n    x_val_score = np.round(np.sqrt(-1*neg_x_val_score), 5)\n    return x_val_score.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [lasso, ridge, elnt, dt, knn, rf, et, ab, gb, xgb, lgb]\ncross_val_scores = []\nfor model in models:\n    cross_val_scores.append(cross_validate(model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_val_score = pd.DataFrame(data = cross_val_scores, columns = ['Cross Validation Scores (RMSE)'])\nx_val_score.index = ['LSO', 'RIDGE', 'ELNT', 'DT', 'KNN', 'RF', 'ET', 'AB', 'GB', 'XGB', 'LGB']\nx_val_score = x_val_score.round(5)\nx = x_val_score.index\ny = x_val_score['Cross Validation Scores (RMSE)']\nsns.scatterplot(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.fit(scaled_train_data,train_labels_mod)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = xgb.predict(scaled_test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preds = target_transformer.inverse_transform(preds)\npreds = np.expm1(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Id = test_data['Customer Id'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {'Customer Id': Id , 'Cost': preds}\nsubmission = pd.DataFrame(data=d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('XGB18.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(scaled_train_data,train_labels_mod,test_size=.2, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = xgb.DMatrix(X_train, label=y_train)\ndtest = xgb.DMatrix(X_test, label=y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n# \"Learn\" the mean from the training data\nmean_train = np.mean(y_train)\n# Get predictions on the test set\nbaseline_predictions = np.ones(y_test.shape) * mean_train\n# Compute MAE\nmae_baseline = mean_absolute_error(y_test, baseline_predictions)\nprint(\"Baseline MAE is {:.2f}\".format(mae_baseline))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    # Parameters that we are going to tune.\n    'max_depth':6,\n    'min_child_weight': 1,\n    'eta':.3,\n    'subsample': 1,\n    'colsample_bytree': 1,\n    # Other parameters\n    'objective':'reg:linear',\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params['eval_metric'] = \"mae\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=9999,\n    evals=[(dtest, \"Test\")],\n    early_stopping_rounds=50\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best MAE: {:.5f} with {} rounds\".format(\n                 model.best_score,\n                 model.best_iteration+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results = xgb.cv(\n    params,\n    dtrain,\n    num_boost_round=9999,\n    seed=42,\n    nfold=5,\n    metrics={'mae'},\n    early_stopping_rounds=50\n)\ncv_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results['test-mae-mean'].min()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# You can try wider intervals with a larger step between\n# each value and then narrow it down. Here after several\n# iteration I found that the optimal value was in the\n# following ranges.\ngridsearch_params = [\n    (max_depth, min_child_weight)\n    for max_depth in range(3,10)\n    for min_child_weight in range(0,7)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''# Define initial best params and MAE\nmin_mae = float(\"Inf\")\nbest_params = None\nfor max_depth, min_child_weight in gridsearch_params:\n    print(\"CV with max_depth={}, min_child_weight={}\".format(\n                             max_depth,\n                             min_child_weight))\n    # Update our parameters\n    params['max_depth'] = max_depth\n    params['min_child_weight'] = min_child_weight\n    # Run CV\n    cv_results = xgb.cv(\n        params,\n        dtrain,\n        num_boost_round=9999,\n        seed=42,\n        nfold=5,\n        metrics={'mae'},\n        early_stopping_rounds=50\n    )\n    # Update best MAE\n    mean_mae = cv_results['test-mae-mean'].min()\n    boost_rounds = cv_results['test-mae-mean'].argmin()\n    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n    if mean_mae < min_mae:\n        min_mae = mean_mae\n        best_params = (max_depth,min_child_weight)\nprint(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params['max_depth'] = 6\nparams['min_child_weight'] = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gridsearch_params = [\n    (subsample, colsample)\n    for subsample in [i/10. for i in range(3,11)]\n    for colsample in [i/10. for i in range(3,11)]\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''min_mae = float(\"Inf\")\nbest_params = None\n# We start by the largest values and go down to the smallest\nfor subsample, colsample in reversed(gridsearch_params):\n    print(\"CV with subsample={}, colsample={}\".format(\n                             subsample,\n                             colsample))\n    # We update our parameters\n    params['subsample'] = subsample\n    params['colsample_bytree'] = colsample\n    # Run CV\n    cv_results = xgb.cv(\n        params,\n        dtrain,\n        num_boost_round=9999,\n        seed=42,\n        nfold=5,\n        metrics={'mae'},\n        early_stopping_rounds=50\n    )\n    # Update best score\n    mean_mae = cv_results['test-mae-mean'].min()\n    boost_rounds = cv_results['test-mae-mean'].argmin()\n    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n    if mean_mae < min_mae:\n        min_mae = mean_mae\n        best_params = (subsample,colsample)\nprint(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params['subsample'] = 1\nparams['colsample_bytree'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''%time\n# This can take some time…\nmin_mae = float(\"Inf\")\nbest_params = None\nfor eta in [.3, .2, .1, .05, .03, .01, .005, .001]:\n    print(\"CV with eta={}\".format(eta))\n    # We update our parameters\n    params['eta'] = eta\n    # Run and time CV\n    cv_results = xgb.cv(\n            params,\n            dtrain,\n            num_boost_round=9999,\n            seed=42,\n            nfold=5,\n            metrics=['mae'],\n            early_stopping_rounds=50\n          )\n    # Update best score\n    mean_mae = cv_results['test-mae-mean'].min()\n    boost_rounds = cv_results['test-mae-mean'].argmin()\n    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n    if mean_mae < min_mae:\n        min_mae = mean_mae\n        best_params = eta\nprint(\"Best params: {}, MAE: {}\".format(best_params, min_mae))'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params['eta'] = .05\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=9999,\n    evals=[(dtest, \"Test\")],\n    early_stopping_rounds=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best MAE: {:.5f} in {} rounds\".format(model.best_score, model.best_iteration+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''num_boost_round = model.best_iteration + 1\nbest_model = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=num_boost_round,\n    evals=[(dtest, \"Test\")]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_absolute_error(best_model.predict(dtest), y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}